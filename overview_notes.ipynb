{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f90d26d6-9075-4b73-87f5-ec7a366ae246",
   "metadata": {},
   "source": [
    "# Spark Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bcc49d-0702-4f9e-b0b7-ff8f9ff92148",
   "metadata": {},
   "source": [
    "## Who, what, when, where, why, how?\n",
    "\n",
    "**Apache Spark**:\n",
    "- platform for dealing with big data\n",
    "- 4vs of big data\n",
    "   - Velocity: its gathered quickly, there's lots of data coming; *streaming* data\n",
    "   - Volume: how big the dataset is; bigger than memory; bigger than storage\n",
    "   - Veracity: reliability of the data -- missing data\n",
    "   - Variety: Different data sources; data is not uniform, not structured\n",
    "   \n",
    "Library/ Platform to help solve these issues. \n",
    "- alternatives: hadoop, dask\n",
    "- who? data scientists and data engineers\n",
    "- where? your laptop; the cloud\n",
    "- when? when its already setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a9626-bf6f-488d-bfcb-c06cc7a145b0",
   "metadata": {},
   "source": [
    "## Spark Architecture\n",
    "\n",
    "- Scala on the JVM(Java Virtual Machine) \n",
    "- Client Libraries--pyspark\n",
    "- Drivers, Executors, Clusters, Cluster Managers\n",
    "   - Driver runs the spark client; directs the cluster manager or master\n",
    "   - Executor is one node in a spark cluster; performs work on data partitions\n",
    "   - Cluster Manger interfaces with client libraries and divides up work amongst executors\n",
    "- Local Mode: all of the above on one computer\n",
    "- the code we write for spark in local mode works just as well with a full cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0d89b-77ba-48e2-b559-d25aa4b8da83",
   "metadata": {},
   "source": [
    "## Parallel Work\n",
    "\n",
    "- Teamwork, but for computers\n",
    "- Tradeoffs and advantages\n",
    "- 2 levels: executors and partitions\n",
    "\n",
    "### Spark Dataframes\n",
    "\n",
    "- not a pandas dataframe\n",
    "- 2 dimensional data structure with named columns\n",
    "- familiar abstraction; abstracts all of the above\n",
    "- lazy: work isn't done until it has to be\n",
    "- SQL: \n",
    "- **transformations** and **actions**: transformations are lazy, actions realize data\n",
    "> It isn't until we apply an action, that spark begins to work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556cc7f-3892-4d32-9708-030d95f44e59",
   "metadata": {},
   "source": [
    "## Lessons Covered\n",
    "\n",
    "1. Overview\n",
    "2. Env Setup\n",
    "3. Spark API\n",
    "4. Data Wrangling\n",
    "5. Data Exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
